# ============================================================
# AI法务智能体系统 - 环境配置示例
# ============================================================
# 使用说明:
# 1. 复制此文件为 .env
# 2. 填写必要的API密钥和配置
# 3. 启动服务
# ============================================================

# ============ 基础配置 ============
DEBUG=false

# ============ LLM配置 ============
# 默认LLM配置 (可通过LLM管理页面在数据库中覆盖)
# 支持的提供商: openai, anthropic, deepseek, qwen, glm, minimax, moonshot, 
#              baichuan, sparkdesk, ernie, hunyuan, doubao, stepfun, yi, 
#              ollama, localai, vllm, xinference, llamacpp, custom
LLM_PROVIDER=deepseek
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.deepseek.com/v1
LLM_MODEL=deepseek-chat
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096

# LLM加密密钥 (用于加密存储在数据库中的API密钥，留空会自动生成)
# 生产环境建议设置固定密钥，否则重启后无法解密已保存的密钥
# LLM_ENCRYPTION_KEY=your-32-byte-base64-key-here

# ============================================================
#                    国产云端大模型配置
# ============================================================

# ------------ DeepSeek (推荐，性价比高) ------------
# 官网: https://platform.deepseek.com
# 模型: deepseek-chat, deepseek-coder, deepseek-reasoner
# LLM_PROVIDER=deepseek
# LLM_API_KEY=sk-your-deepseek-key
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_MODEL=deepseek-chat

# ------------ 阿里通义千问 Qwen ------------
# 官网: https://dashscope.console.aliyun.com
# 文本模型: qwen-max, qwen-max-longcontext, qwen-plus, qwen-turbo, qwen-long
#          qwen2.5-72b-instruct, qwen2.5-32b-instruct, qwen2.5-14b-instruct
#          qwen2.5-coder-32b-instruct
# 多模态模型: qwen-vl-max, qwen-vl-plus (支持图像理解)
# LLM_PROVIDER=qwen
# LLM_API_KEY=sk-your-qwen-key
# LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_MODEL=qwen-max

# ------------ 智谱 GLM ------------
# 官网: https://open.bigmodel.cn
# 文本模型: glm-4-plus, glm-4-0520, glm-4-air, glm-4-airx, glm-4-long, glm-4-flash
# 多模态模型: glm-4v-plus, glm-4v (支持图像理解)
# LLM_PROVIDER=glm
# LLM_API_KEY=your-glm-key
# LLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# LLM_MODEL=glm-4-plus

# ------------ Minimax ------------
# 官网: https://www.minimaxi.com
# 模型: abab6.5s-chat, abab6.5g-chat, abab6.5t-chat, abab5.5s-chat, abab5.5-chat
# LLM_PROVIDER=minimax
# LLM_API_KEY=your-minimax-key
# LLM_BASE_URL=https://api.minimax.chat/v1
# LLM_MODEL=abab6.5s-chat

# ------------ 月之暗面 Kimi ------------
# 官网: https://platform.moonshot.cn
# 模型: moonshot-v1-128k, moonshot-v1-32k, moonshot-v1-8k
# LLM_PROVIDER=moonshot
# LLM_API_KEY=sk-your-moonshot-key
# LLM_BASE_URL=https://api.moonshot.cn/v1
# LLM_MODEL=moonshot-v1-128k

# ------------ 百川智能 ------------
# 官网: https://platform.baichuan-ai.com
# 模型: Baichuan4, Baichuan3-Turbo, Baichuan3-Turbo-128k, Baichuan2-Turbo
# LLM_PROVIDER=baichuan
# LLM_API_KEY=your-baichuan-key
# LLM_BASE_URL=https://api.baichuan-ai.com/v1
# LLM_MODEL=Baichuan4

# ------------ 字节豆包 ------------
# 官网: https://www.volcengine.com/product/doubao
# 模型: doubao-pro-256k, doubao-pro-128k, doubao-pro-32k, doubao-pro-4k
#      doubao-lite-128k, doubao-lite-32k, doubao-lite-4k
# LLM_PROVIDER=doubao
# LLM_API_KEY=your-doubao-key
# LLM_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
# LLM_MODEL=doubao-pro-128k

# ------------ 零一万物 Yi ------------
# 官网: https://platform.lingyiwanwu.com
# 文本模型: yi-lightning, yi-large, yi-large-turbo, yi-large-rag, 
#          yi-medium, yi-medium-200k, yi-spark
# 多模态模型: yi-vision (支持图像理解)
# LLM_PROVIDER=yi
# LLM_API_KEY=your-yi-key
# LLM_BASE_URL=https://api.lingyiwanwu.com/v1
# LLM_MODEL=yi-large

# ------------ 阶跃星辰 StepFun ------------
# 官网: https://platform.stepfun.com
# 文本模型: step-2-16k, step-1-256k, step-1-128k, step-1-32k, step-1-8k
# 多模态模型: step-1v-32k, step-1v-8k (支持图像理解)
# LLM_PROVIDER=stepfun
# LLM_API_KEY=your-stepfun-key
# LLM_BASE_URL=https://api.stepfun.com/v1
# LLM_MODEL=step-2-16k

# ------------ 讯飞星火 ------------
# 官网: https://xinghuo.xfyun.cn
# 模型: 4.0Ultra, generalv3.5, generalv3, generalv2, general
# 注意: API密钥格式为 APIKey:APISecret
# LLM_PROVIDER=sparkdesk
# LLM_API_KEY=your-apikey:your-apisecret
# LLM_BASE_URL=https://spark-api-open.xf-yun.com/v1
# LLM_MODEL=4.0Ultra

# ------------ 百度文心一言 ------------
# 官网: https://cloud.baidu.com/product/wenxinworkshop
# 模型: ernie-4.0-8k, ernie-4.0-turbo-8k, ernie-3.5-8k, ernie-3.5-128k
#      ernie-speed-8k, ernie-speed-128k, ernie-lite-8k
# 注意: 需要使用Access Token
# LLM_PROVIDER=ernie
# LLM_API_KEY=your-access-token
# LLM_BASE_URL=https://aip.baidubce.com
# LLM_MODEL=ernie-4.0-8k

# ------------ 腾讯混元 ------------
# 官网: https://cloud.tencent.com/product/hunyuan
# 模型: hunyuan-pro, hunyuan-standard, hunyuan-lite, hunyuan-code, 
#      hunyuan-role, hunyuan-vision
# 注意: 需要SecretId和SecretKey
# LLM_PROVIDER=hunyuan
# LLM_API_KEY=your-secret-id:your-secret-key
# LLM_BASE_URL=https://hunyuan.tencentcloudapi.com
# LLM_MODEL=hunyuan-pro

# ============================================================
#                    本地大模型部署配置
# ============================================================

# ------------ Ollama (推荐，最简单) ------------
# 官网: https://ollama.ai
# 安装后运行: ollama run qwen2.5:32b
# 支持模型: qwen2.5, qwen2.5:32b, deepseek-r1, llama3.2, gemma2, mistral, codellama, phi3
# LLM_PROVIDER=ollama
# LLM_API_KEY=
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=qwen2.5:32b

# ------------ vLLM (推荐，高性能推理) ------------
# 官网: https://docs.vllm.ai
# 启动命令: python -m vllm.entrypoints.openai.api_server --model Qwen/Qwen2.5-32B-Instruct
# 支持任意 HuggingFace 模型
# LLM_PROVIDER=vllm
# LLM_API_KEY=
# LLM_BASE_URL=http://localhost:8000/v1
# LLM_MODEL=Qwen/Qwen2.5-32B-Instruct

# ------------ Xinference (推荐，图形界面管理) ------------
# 官网: https://inference.readthedocs.io
# 安装: pip install xinference[all]
# 启动: xinference-local
# 然后在 http://localhost:9997 界面部署模型
# LLM_PROVIDER=xinference
# LLM_API_KEY=
# LLM_BASE_URL=http://localhost:9997/v1
# LLM_MODEL=qwen2.5-instruct

# ------------ LocalAI ------------
# 官网: https://localai.io
# 支持 GGUF 格式模型
# LLM_PROVIDER=localai
# LLM_API_KEY=
# LLM_BASE_URL=http://localhost:8080/v1
# LLM_MODEL=your-model-name

# ------------ llama.cpp Server ------------
# 官网: https://github.com/ggerganov/llama.cpp
# 启动: ./llama-server -m your-model.gguf --port 8080
# LLM_PROVIDER=llamacpp
# LLM_API_KEY=
# LLM_BASE_URL=http://localhost:8080/v1
# LLM_MODEL=your-model-name

# ------------ 自定义 OpenAI 兼容接口 ------------
# 任何兼容 OpenAI API 格式的服务都可以使用
# LLM_PROVIDER=custom
# LLM_API_KEY=your-api-key
# LLM_BASE_URL=http://your-custom-endpoint/v1
# LLM_MODEL=your-model-name

# ============================================================
#                    Embedding 向量模型配置
# ============================================================

# 是否使用本地Embedding模型 (推荐用于隐私敏感场景)
USE_LOCAL_EMBEDDING=false
LOCAL_EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5

# 云端 Embedding 配置 (与LLM使用相同API Key时可省略)
EMBEDDING_API_KEY=sk-your-api-key-here
EMBEDDING_BASE_URL=https://api.openai.com/v1
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSIONS=3072

# 通义千问 Embedding
# EMBEDDING_API_KEY=sk-your-qwen-key
# EMBEDDING_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# EMBEDDING_MODEL=text-embedding-v3
# EMBEDDING_DIMENSIONS=1024

# 智谱 Embedding
# EMBEDDING_API_KEY=your-glm-key
# EMBEDDING_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# EMBEDDING_MODEL=embedding-3
# EMBEDDING_DIMENSIONS=2048

# Ollama 本地 Embedding
# EMBEDDING_API_KEY=
# EMBEDDING_BASE_URL=http://localhost:11434/v1
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768

# ============ 数据库配置 ============
# PostgreSQL (Docker默认配置)
DATABASE_URL=postgresql://postgres:password@localhost:5432/legal_agent_db
DATABASE_POOL_SIZE=10

# Redis缓存
REDIS_URL=redis://localhost:6379/0

# ============ 向量数据库配置 ============
# Qdrant向量数据库
QDRANT_URL=http://localhost:6333
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=legal_knowledge

# RAG检索配置
RAG_TOP_K=5
RAG_CHUNK_SIZE=500
RAG_CHUNK_OVERLAP=50
RAG_SCORE_THRESHOLD=0.5
RAG_CONTEXT_MAX_LENGTH=4000

# Neo4j图数据库
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# ============ 对象存储配置 ============
# MinIO对象存储
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=admin
MINIO_SECRET_KEY=password
MINIO_BUCKET=legal-documents

# ============ 安全配置 ============
# JWT认证 (生产环境请更换密钥)
JWT_SECRET_KEY=your-super-secret-jwt-key-please-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=1440

# ============ 搜索服务配置 ============
SEARCH_PROVIDER=perplexity
SEARCH_API_KEY=your-search-api-key

# ============ 日志配置 ============
LOG_LEVEL=INFO
LOG_FORMAT=json

# ============ 服务端口 ============
BACKEND_PORT=8001
FRONTEND_PORT=3000

# ============ 第三方API (可选) ============
# 企查查API (用于尽职调查)
# QICHACHA_API_KEY=your-qichacha-api-key

# 天眼查API (用于企业信息查询)
# TIANYANCHA_API_KEY=your-tianyancha-api-key
